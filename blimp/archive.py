"""Convert Nikon nd2 files to standard open microscopy environment formats."""
from typing import Dict, List, Union
from pathlib import Path
from datetime import datetime
import os
import re
import glob
import stat
import logging

import numpy as np

from blimp.preprocessing.convert_nd2 import find_nd2_files
from blimp.preprocessing.convert_operetta import find_images_dirs

logger = logging.getLogger(__name__)


def check_config_file() -> bool:
    """Check that the config file exists in the correct location"""
    config_path = Path.home() / "config.cfg"
    if not config_path.exists():
        logger.error(
            f"Config file not found at {config_path}. Please use get-config-file from UNSW's data archive module"
        )
        os._exit(1)
    else:
        return True


def write_archiving_script_nd2(
    file_paths: Union[List[Path], List[str]],
    script_path: Union[Path, str],
    first_name: str,
    project_name: str = "D0419427",
) -> None:
    """
    Create a bash script that execute the 'upload.sh' command for each file path in `file_paths` list.
    The script will be saved in the current working directory with name 'upload_script.sh'

    Parameters
    ----------
    file_paths : list of str
        list of file paths to be uploaded

    Returns
    -------
    None
    """

    file_paths = [str(f) for f in file_paths]

    with open(Path(script_path), "w") as f:
        f.write("#!/bin/bash\n\n")
        f.write("## Archiving script generated by BLIMP's archive tool\n\n")
        f.write("## Inputs:\n")
        f.write(f"##     First name: {first_name}\n")
        f.write(f"##     Project:    {project_name}\n\n")
        f.write("module add unswdataarchive/2021-02-17\n\n")
        f.write("export CONFIG_FILE=${HOME}/config.cfg\n\n")
        for file_path in file_paths:
            # use a regex to strip the first part of the filename that
            # we do not need to include in the upload destination
            relative_path = re.sub(r"^\/srv\/scratch\/berrylab\/z\d{7}\/", "", file_path)
            f.write(
                f"java -Dmf.cfg=$CONFIG_FILE -cp /apps/unswdataarchive/2021-02-17/aterm.jar arc.mf.command.Execute import -verbose true -import-empty-folders true -namespace /UNSW_RDS/{project_name}/{first_name}/{relative_path} {file_path}\n"
            )


def split_operetta_files_into_archiving_batches(images_dir: Union[Path, str]) -> Dict[str, List[str]]:
    """Splits filenames into groups based on the 'r00c00' pattern.

    Parameters
    ----------
        images_dir: string or pathlib.Path of the 'Images' directory.

    Returns
    -------
        A dictionary containing groups of filenames as values,
        with the 'r00c00' pattern as keys.
    """

    filenames = os.listdir(images_dir)
    groups: Dict[str, List[str]] = {}

    pattern = r"r(\d{2})c(\d{2})"  # Regular expression pattern for 'r00c00'
    for filename in filenames:
        match = re.search(pattern, filename)
        if match:
            key = match.group()  # Get the matched pattern
            if key not in groups:
                groups[key] = []
            groups[key].append(filename)

    return groups


def write_archiving_batch_files(
    archive_dir: Union[Path, str], images_dir: Union[Path, str], groups: Dict[str, List[str]]
) -> None:
    """Writes groups of filenames to separate text files,
    for use as input to `tar` with the '-T' option.

    Parameters
    ----------
        groups: A dictionary containing groups of filenames,
        where keys are 'r00c00' patterns and values are lists
        of filenames.
    """
    archive_dir = Path(archive_dir)
    images_dir = Path(images_dir)
    for key, filenames in groups.items():
        file_name = archive_dir / (key + ".txt")
        with open(file_name, "w") as file:
            for filename in filenames:
                file.write((str(images_dir / filename)) + "\n")


def write_archiving_script_operetta(
    file_paths: Union[List[Path], List[str]],
    script_path: Union[Path, str],
    first_name: str,
    project_name: str = "D0419427",
) -> None:
    """
    Create a bash script that execute the 'upload.sh' command for each file path in `file_paths` list.
    The script will be saved in the current working directory with name 'upload_script.sh'

    Parameters
    ----------
    file_paths : list of str
        list of file paths to be uploaded

    Returns
    -------
    None
    """

    file_paths = [str(f) for f in file_paths]

    with open(Path(script_path), "w") as f:
        f.write("#!/bin/bash\n\n")
        f.write("## Archiving script generated by BLIMP's archive tool\n\n")
        f.write("## Inputs:\n")
        f.write(f"##     First name: {first_name}\n")
        f.write(f"##     Project:    {project_name}\n\n")
        f.write("module add unswdataarchive/2021-02-17\n\n")
        f.write("export CONFIG_FILE=${HOME}/config.cfg\n\n")
        f.write("## Compress into batch files:\n\n")
        for file_path in file_paths:
            if Path(file_path).stem == "Archive":
                archive_batch_files = glob.glob(str(Path(file_path) / "*.txt"))
                for batch_file in archive_batch_files:
                    f.write(f"tar -cvzf {str(Path(batch_file).with_suffix('.tar.gz'))} -T {batch_file}\n")
        f.write("\n## Upload:\n\n")
        for file_path in file_paths:
            # use a regex to strip the first part of the filename that
            # we do not need to include in the upload destination
            relative_path = re.sub(r"^\/srv\/scratch\/berrylab\/z\d{7}\/", "", file_path)
            f.write(
                f"java -Dmf.cfg=$CONFIG_FILE -cp /apps/unswdataarchive/2021-02-17/aterm.jar arc.mf.command.Execute import -verbose true -import-empty-folders true -namespace /UNSW_RDS/{project_name}/{first_name}/{relative_path} {file_path}\n"
            )
        f.write("\n## Remove compressed data locally:\n\n")
        for batch_file in archive_batch_files:
            f.write(f"rm {str(Path(batch_file).with_suffix('.tar.gz'))} \n")


def archive(
    in_path: Union[Path, str], jobscript_path: Union[Path, str], first_name: str, project_name: str, input_type: str
) -> None:
    """
    Archive image files or directories using the specified input type.

    Parameters
    ----------
    in_path
        The path to the input image files or directories.
    job_path
        The path to the job directory where the archiving script will be written.
    input_type
        The type of input, either "nd2" or "operetta".

    Returns
    -------
    None

    Raises
    ------
    ValueError
        If input_type is not "nd2" or "operetta".
    """

    check_config_file()

    today = datetime.today().strftime("%Y-%m-%d")

    in_path = Path(in_path)
    jobscript_path = Path(jobscript_path) / ("archive_data_blimp_" + today + ".sh")

    if input_type == "nd2":
        # Archive nd2 files individually since
        # these tend to be few in number
        image_files = find_nd2_files(in_path)
        write_archiving_script_nd2(image_files, jobscript_path, first_name, project_name)

    elif input_type == "operetta":
        # Archive 'Images' directories after compressing into batches
        # include also associated metadata folders
        image_dirs = find_images_dirs(in_path)
        for image_dir in image_dirs:
            # create archive directory if it does not exist
            archive_dir = Path(image_dir).parent / "Archive"
            if not archive_dir.exists():
                archive_dir.mkdir(parents=True, exist_ok=True)
            # split file list into batches and write as text files
            batches = split_operetta_files_into_archiving_batches(image_dir)
            write_archiving_batch_files(archive_dir=archive_dir, images_dir=image_dir, groups=batches)
        sub_dirs = ["Archive", "Assaylayout", "FFC_Profile"]
        archive_dirs = np.concatenate([[Path(d).parent / s for s in sub_dirs] for d in image_dirs])
        write_archiving_script_operetta(archive_dirs.flatten(), jobscript_path, first_name, project_name)

    else:
        logger.error(f"input_type {input_type} not recognised. Please specify 'nd2' or 'operetta' input_type.")
        raise ValueError("Input type not recognised")

    os.chmod(jobscript_path, stat.S_IRWXU | stat.S_IRWXG | stat.S_IROTH)

    return
